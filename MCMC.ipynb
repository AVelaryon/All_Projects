{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations, count\n",
    "from numpy.linalg import det, inv, norm\n",
    "from dsci_project_assignment import Gradient_Descent\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from scipy.stats import multivariate_normal as multi_n\n",
    "from scipy.stats import uniform as uni\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "# Fetching Data:\n",
    "data  = fetch_california_housing(as_frame=True)['frame'].copy()\n",
    "data = np.c_[np.ones((data.shape[0],1)),data.to_numpy()]\n",
    "\n",
    "# data.AveBedrms = np.ceil(data.AveBedrms.mul(data.Population))\n",
    "# data.AveOccup = np.ceil(data.AveOccup.mul(data.Population))\n",
    "# data['Bedrms_per_Hhld'] = data.AveBedrms.div(data.AveOccup)\n",
    "# data.AveRooms = np.ceil(data.AveRooms.mul(data.Population))\n",
    "# data.drop(columns =['Population'], inplace=True)\n",
    "# data.iloc[:, [7,8]] = data.iloc[:, [8,7]]\n",
    "# data.rename(columns={'MedHouseVal':'Bedrms_per_Hhld', 'Bedrms_per_Hhld':'MedHouseVal'}, inplace=True)\n",
    "\n",
    "\n",
    "# Train/Val/Test Split:\n",
    "val = train_test_split(data[:,:-1],data[:,-1], train_size=0.8, random_state=0)\n",
    "\n",
    "\n",
    "# Kernel:\n",
    "def kernel(data: pd.DataFrame):\n",
    "    rows,columns= data.shape\n",
    "    K = np.zeros((columns,columns))\n",
    "    for i in range(columns):\n",
    "        for j in range(columns):\n",
    "            K[i,j] = np.exp((-1/2)*norm(data[i]-data[j])**2)\n",
    "    return K\n",
    "# print(kernel(val[0]))\n",
    "def weight_prior(weights: np.ndarray, dims: int, mean: np.ndarray[float], kernel: np.ndarray[float]):\n",
    "    return multi_n.logpdf(weights, mean=mean, cov=kernel)\n",
    "# Multivariate Posterior \n",
    "def observe_variance(y_pred: np.ndarray, y_true: np.ndarray, dim: int):\n",
    "    n = len(y_pred)\n",
    "    residuals = np.sum(np.square(y_true-y_pred))/(n-dim)\n",
    "    return residuals\n",
    "def maximum_likelihood(data: np.ndarray, y_true: np.ndarray, w_mean: np.ndarray, w_var: np.ndarray):\n",
    "    rows, columns = data.shape\n",
    "    weights = multi_n.rvs(mean=w_mean, cov=w_var, size=1)\n",
    "    y_pred = data.dot(weights)\n",
    "    obs_var = np.square(y_pred-y_true).mean()\n",
    "    lhood = np.sum(np.log((1/np.sqrt(2*np.pi*obs_var))*np.exp(-np.square(y_true-y_pred)/(2*obs_var))))\n",
    "    obs_var = np.square(data.dot(weights)-y_true).mean()\n",
    "    return weights, obs_var\n",
    "def multi_likelihood(y_pred: np.ndarray, y_true: list, obs_var: float):\n",
    "    '''\n",
    "    Returns p(y|X,w)\n",
    "    '''\n",
    "    n = len(y_pred)\n",
    "    post  = np.sum(np.log((1/np.sqrt(2*np.pi*obs_var))*np.exp(-np.square(y_true-y_pred)/(2*obs_var))))\n",
    "    return post\n",
    "def marginal_likelihood(data: np.ndarray, y_true: np.ndarray, obs_var: float, dims: int, w_samp: int, w_mean: np.ndarray, w_var: np.ndarray):\n",
    "    '''\n",
    "    Novice attempt at approximating the marginal likelihood.\n",
    "    Returns p(y|X): summing over the weights\n",
    "    **This approach requires mcmc for better accuracy; thus, don't use this callable in practice.**\n",
    "    '''\n",
    "    n = len(data)\n",
    "    weight_samp = multi_n.rvs(mean=w_mean, cov=w_var, size=w_samp)\n",
    "    marg = -np.inf\n",
    "    for w in weight_samp:\n",
    "        # print(w)\n",
    "        marg = np.logaddexp(marg, multi_likelihood(data.dot(w), y_true, obs_var) + weight_prior(w, dims, w_mean, w_var))\n",
    "    return marg - np.log(w_samp)\n",
    "\n",
    "def alt_weight_post(data: np.ndarray, y: np.ndarray, w: np.ndarray, obs_var: float, w_var: float):\n",
    "    sigma_n = np.linalg.inv(data.T.dot(data)/obs_var + np.linalg.inv(w_var))\n",
    "    wn = np.dot(sigma_n, np.dot(data.T, y)/obs_var +np.dot(np.linalg.inv(w_var), w))\n",
    "    return wn, sigma_n\n",
    "\n",
    "\n",
    "def mcmc(y_true, y_pred, obs_var, dims):\n",
    "    weight_i1 = multi_n.rvs(mean=np.zeros((dims, )), cov=np.eye(dims))\n",
    "    weight = []\n",
    "    for i in count():\n",
    "        weight_i2 = uni.rvs(loc = np.zeros((dims,)), scale=1)\n",
    "        prior_i1 = multi_n.pdf()\n",
    "        lhood_i = multi_likelihood(y_pred, y_true,obs_var)\n",
    "    pass \n",
    "\n",
    "\n",
    "transformer = QuantileTransformer(n_quantiles=5000, output_distribution='normal', random_state=0)\n",
    "\n",
    "# Scaled Training Data:\n",
    "transformer.fit(val[0])\n",
    "XS = transformer.transform(val[0])\n",
    "\n",
    "# # normali = lambda x: (x-x.min())/(x.max()-x.min())\n",
    "# # XS = val[0].copy()\n",
    "# # Performing Gradient Descent:\n",
    "# gd = Gradient_Descent(XS, val[2], 1e-10)\n",
    "# newtheta,*_ = gd.fit(1e-3)\n",
    "\n",
    "# w, obs_var = maximum_likelihood(XS, val[2], np.zeros((9,)), np.eye(9))\n",
    "# wn, sigma_n = alt_weight_post(XS, val[2], w, obs_var, np.eye(9))\n",
    "\n",
    "# w_var = np.eye(9)\n",
    "# w_mean = np.zeros((9,))\n",
    "# weight_set = list()\n",
    "# train_var = list()\n",
    "# for i in range(1000):\n",
    "#     w, obs_var = maximum_likelihood(XS, val[2],w_mean,w_var)\n",
    "#     train_var.append(obs_var)\n",
    "#     wn, sigma_n = alt_weight_post(XS, val[2], w, obs_var, w_var)\n",
    "#     w_var = sigma_n\n",
    "#     w_mean = wn\n",
    "#     weight_set.append(w)  \n",
    "\n",
    "# print(f'Initial Weights:{weight_set[0]} with model variance: {np.square(XS.dot(weight_set[0])-val[2]).mean()}')\n",
    "# best_var = min(train_var)\n",
    "# best_param = weight_set[train_var.index(best_var)]\n",
    "# print(f' Last Weight:{best_param} with model variance:{np.square(XS.dot(best_param)-val[2]).mean()}')\n",
    "# prior_w = multi_n.logpdf(newtheta, mean=np.zeros((9,)), cov=np.eye(9))\n",
    "# XBIAS = np.c_[np.ones((XS.shape[0],1)), XS]\n",
    "# print(gd.loglikelihood(8))\n",
    "# sigma2 = observe_variance(XBIAS.dot(newtheta), val[2].to_numpy(), 9)\n",
    "# w_mean, w_vari = alt_weight_post(XBIAS, val[2].to_numpy(), newtheta, sigma2, np.eye(9))\n",
    "# print(multi_n.pdf(XBIAS,mean=w_mean, cov=w_vari))\n",
    "# print(f'Observed Variance:{sigma2}')\n",
    "# print(f'Likelihood:{multi_likelihood(XBIAS.dot(newtheta), val[2].to_numpy(), sigma2)}')\n",
    "# print(f'Marginal Likelihood:{marginal_likelihood(XBIAS, val[2].to_numpy(), sigma2, 9,w_samp=5000, w_mean=np.zeros((9,)),w_var=np.eye(9))}')\n",
    "# print(f'Exponential Probability of Parameters:{(multi_likelihood(XBIAS.dot(newtheta), val[2].to_numpy(), sigma2)+prior_w)-(marginal_likelihood(XBIAS, val[2].to_numpy(), sigma2, 9,w_samp=5000, w_mean=np.zeros((9,)),w_var=np.eye(9)))}')\n",
    "# print(kernel(XBIAS.dot(newtheta)))\n",
    "# post_y = multi_likelihood(XBIAS.dot(newtheta), val[2].to_numpy(), sigma2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(y_pred, y_true, obs_var):\n",
    "    '''\n",
    "    Returns p(y|X,w)\n",
    "    '''\n",
    "    n = len(y_true)\n",
    "    post  = np.sum(np.log((1/np.sqrt(2*np.pi*obs_var))*np.exp(-np.square(y_true-y_pred)/(2*obs_var))))\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(data):\n",
    "    w,w1 = data\n",
    "    n = len(w)\n",
    "    K = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i,j] = np.exp((-1/(2*10))*np.linalg.norm(w1[i]-w[j])**2)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_likelihood(data, y_true):\n",
    "    '''\n",
    "    This function attempts to find all such weights (w) that\n",
    "    likely explains output distribution. I wish to compute the marginal \n",
    "    likelihood.\n",
    "    '''\n",
    "    w = ss.multivariate_normal.rvs(mean=np.zeros((data.shape[1],)), cov=np.eye(data.shape[1]), size=1)\n",
    "    uni = ss.uniform.rvs(loc=np.zeros((data.shape[1],)))\n",
    "    wl = [w,uni]\n",
    "    for _ in range(100):\n",
    "        y_pred = data.dot(w)\n",
    "        error = np.mean(np.square(y_true-y_pred))\n",
    "        llhood_w = likelihood(y_pred, y_true, error)\n",
    "        y_pred_u = data.dot(uni)\n",
    "        error_u = np.mean(np.square(y_true-y_pred_u))\n",
    "        llhood_u = likelihood(y_pred, y_true, error_u)\n",
    "        if min(1,llhood_u-llhood_w)>=1:\n",
    "            wl.append(uni)\n",
    "            kernel_mat = kernel(wl[-2:])\n",
    "            print(kernel_mat)\n",
    "            print(wl)\n",
    "            w = ss.multivariate_normal.rvs(mean=uni, cov=kernel_mat, size=1)\n",
    "            uni = ss.uniform.rvs(loc=w)\n",
    "        elif min(1,llhood_u-llhood_w)>0 and min(1,llhood_u-llhood_w)<1:\n",
    "            wl.append(uni)\n",
    "            uni = ss.uniform.rvs(loc=uni, size=1)\n",
    "            \n",
    "        else:\n",
    "            wl.append(wl[-1])\n",
    "\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights:\t[[ 1.35771808]\n",
      " [ 1.81645559]\n",
      " [-1.92472538]\n",
      " [ 0.49946095]]\n"
     ]
    }
   ],
   "source": [
    "X = np.c_[np.random.normal(loc=0, scale=1, size=(1000, 3)), np.ones(shape=(1000,))]\n",
    "weight = np.random.randn(4,1)\n",
    "print(f'Model Weights:\\t{weight}')\n",
    "y = X.dot(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99797257 0.995316   0.9941643 ]\n",
      " [0.99797257 1.         0.9871847  0.99901115]\n",
      " [0.995316   0.9871847  1.         0.97918777]\n",
      " [0.9941643  0.99901115 0.97918777 1.        ]]\n",
      "[array([1.0344254 , 1.34447336, 0.03621648, 0.8394635 ]), array([0.3998989 , 0.60136786, 0.09346779, 0.74203332]), array([0.3998989 , 0.60136786, 0.09346779, 0.74203332])]\n",
      "[[0.88971763 0.91568633 0.84502315 0.93202025]\n",
      " [0.86760795 0.89575276 0.82007965 0.91374156]\n",
      " [0.97848569 0.98956376 0.95441736 0.99497561]\n",
      " [0.93511419 0.95525274 0.89827724 0.96723972]]\n",
      "[array([1.0344254 , 1.34447336, 0.03621648, 0.8394635 ]), array([0.3998989 , 0.60136786, 0.09346779, 0.74203332]), array([0.3998989 , 0.60136786, 0.09346779, 0.74203332]), array([1.92863128, 2.08521986, 1.05943077, 1.55823074])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The input matrix must be symmetric positive semidefinite.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mdependent_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m [np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msquare(y \u001b[38;5;241m-\u001b[39m X\u001b[38;5;241m.\u001b[39mdot(weights[i]))) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(weights))]\n",
      "Cell \u001b[1;32mIn[205], line 22\u001b[0m, in \u001b[0;36mdependent_likelihood\u001b[1;34m(data, y_true)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(kernel_mat)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(wl)\n\u001b[1;32m---> 22\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muni\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     uni \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39muniform\u001b[38;5;241m.\u001b[39mrvs(loc\u001b[38;5;241m=\u001b[39mw)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (llhood_u\u001b[38;5;241m/\u001b[39mllhood_w)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (llhood_u\u001b[38;5;241m/\u001b[39mllhood_w)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dwigh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:753\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.rvs\u001b[1;34m(self, mean, cov, size, random_state)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrvs\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    733\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Draw random samples from a multivariate normal distribution.\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \n\u001b[0;32m    735\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    751\u001b[0m \n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 753\u001b[0m     dim, mean, cov_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_random_state(random_state)\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cov_object, _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD):\n",
      "File \u001b[1;32mc:\\Users\\dwigh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:422\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[1;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    415\u001b[0m dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_psd(\u001b[38;5;28;01mNone\u001b[39;00m, mean, cov)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m psd \u001b[38;5;241m=\u001b[39m \u001b[43m_PSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m cov_object \u001b[38;5;241m=\u001b[39m _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD(psd)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dim, mean, cov_object\n",
      "File \u001b[1;32mc:\\Users\\dwigh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:172\u001b[0m, in \u001b[0;36m_PSD.__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(s) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39meps:\n\u001b[0;32m    171\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input matrix must be symmetric positive semidefinite.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    173\u001b[0m d \u001b[38;5;241m=\u001b[39m s[s \u001b[38;5;241m>\u001b[39m eps]\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_singular:\n",
      "\u001b[1;31mValueError\u001b[0m: The input matrix must be symmetric positive semidefinite."
     ]
    }
   ],
   "source": [
    "weights = dependent_likelihood(X, y)\n",
    "[np.mean(np.square(y - X.dot(weights[i]))) for i in range(len(weights))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.09516326,  0.26647949,  1.33712927, -0.06594478]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ]),\n",
       " array([0.33839761, 0.60316189, 0.54867887, 0.4981603 ])]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59344603],\n",
       "       [0.86048422],\n",
       "       [0.74007223],\n",
       "       [0.91575087]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
